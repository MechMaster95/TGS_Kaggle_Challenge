{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TGS Challenge",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MechMaster95/TGS_Kaggle_Challenge/blob/master/TGS_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-pWs4B_1Nyi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### dependencies installation\n",
        "\n",
        "!pip install imagio\n",
        "!pip install torch\n",
        "!pip install kaggle\n",
        "!pip install ipywidgets\n",
        "####some visualisation package\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ne_jGmAgPhDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q9iHXV8GP0uj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##import dependecies\n",
        "!pip install imageio\n",
        "import os\n",
        "import numpy as np\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ncCz3gPBQ9mN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#upload kaggle credentials\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVm6mpxdR9lN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#is it there?\n",
        "ls -lha kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "48L6feUhSPHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#File Configuration\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1b3140yLTCEI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c tgs-salt-identification-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5eZ8_XzSTSlc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#unzip the files\n",
        "!ls\n",
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VuDALHJKTu5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Lets a create a class to represent our dataset\n",
        "class TGSSaltDataset(data.Dataset):\n",
        "  \n",
        "  def __init__(self, root_path, file_list):\n",
        "    self.root_path = root_path\n",
        "    self.file_list = file_list\n",
        "   \n",
        "  def __len__(self):\n",
        "    return len(self.file_list)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    # oif the index is out of bounds, get a random image\n",
        "    if index not in range(0,len(self.file_list)):\n",
        "      return self.__getitem__(np.random.randint(0, self.__len__()))\n",
        "    \n",
        "    file_id = self.file_list[index]\n",
        "    \n",
        "    #image folder+path\n",
        "    image_folder = os.path.join(self.root_path, 'images')\n",
        "    image_path = os.path.join(image_folder, file_id + '.png')\n",
        "    \n",
        "    \n",
        "    #label folder + path \n",
        "    mask_folder = os.path.join(self.root_path, 'masks')\n",
        "    mask_path = os.path.join(mask_folder, file_id + '.png')\n",
        "    \n",
        "    #read it\n",
        "    image = np.array(imageio.imread(image_path),dtype=np.uint8)\n",
        "    mask = np.array(imageio.imread(mask_path), dtype=np.uint8)\n",
        "    \n",
        "    return image,mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0UvvUClrXB_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_mask = pd.read_csv('train.csv')\n",
        "depth = pd.read_csv('depths.csv')\n",
        "train_path='./'\n",
        "file_list = list(train_mask['id'].values)\n",
        "dataset = TGSSaltDataset(train_path, file_list)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1RrBfz9qYTNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fucntion to visualise the images\n",
        "def plot2x2array(image,mask):\n",
        "  #invoke matplotlib:\n",
        "  f, axarr = plt.subplots(1,2)\n",
        "  axarr[0].imshow(image)\n",
        "  axarr[1].imshow(mask)\n",
        "  axarr[0].grid()\n",
        "  axarr[1].grid()\n",
        "  axarr[0].set_title('Image')\n",
        "  axarr[1].set_title('Mask')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYTIkCnNZTgt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print the image\n",
        "for i in range(5):\n",
        "  image, mask = dataset[np.random.randint(0, len(dataset))]\n",
        "  plot2x2array(image,mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_-cDxYkjKkZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (6,6))\n",
        "plt.hist(depth['z'])\n",
        "plt.title('depth distribution')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YEUjF_nml2X_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Run length Encoding \n",
        "\n",
        "compressing 8 white pixels as 8w or something"
      ]
    },
    {
      "metadata": {
        "id": "V5qL3V9blRit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### OCnvert run length encoding to images that can be imput into our model\n",
        "def rletoMask(rleString, height, width):\n",
        "#width, height\n",
        "  rows, cols = height, width\n",
        "  try:\n",
        "    rleNumbers = [int(numstring) for numstring in rleString.split('')]\n",
        "    rlePairs = np.array(rleNumbers).reshape(-1,2)\n",
        "    img = np.zeros(row*colw, dtype=np.uint8)\n",
        "    for index, length in rlePairs:\n",
        "      index -=1\n",
        "      img[imdex:idex+length]=255\n",
        "     \n",
        "    img = img.reshape(cols, row)\n",
        "    img = img.T\n",
        "    \n",
        "  except:\n",
        "    img = np.zeros((cols,rows))\n",
        "   \n",
        "  return img\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBV4SAfr4Wa9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#function for measuring how salty an image is\n",
        "def salt_proportion (imgArray):\n",
        "  try:\n",
        "    unique, counts =np.unique(imgArray, return_counts=True)\n",
        "    return counts[1]/1021\n",
        "  \n",
        "  except:\n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QpJ-2His5Fza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#prepare to merge depth\n",
        "train_mask['mask']=train_mask['rle_mask'].apply(lambda x: rletoMask(x,101,101))\n",
        "train_mask['salt_proportion']=train_mask['mask'].apply(lambda x:salt_proportion(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SiQSvVMZ5-F4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#merge it\n",
        "merged = train_mask.merge(depth, how = 'left')\n",
        "merged.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FcYpwgEq6Js1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#show proportion of salt vs depth\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.scatter(merged['salt_proportion'],merged['z'])\n",
        "plt.title('Proprtion of salt vs depth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGdRpTm56he5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#how correlated are they\n",
        "\n",
        "print(\"Correlation: \", np.corrcoef(merged['salt_proportion'], merged['z'])[0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_8tls2JJ8RHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpHtCfGl8k4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_width = 128\n",
        "im_height = 128\n",
        "border = 5\n",
        "im_chan = 2 # Number of channels: first is original and second cumsum(axis=0)\n",
        "n_features = 1 # Number of extra features, like depth\n",
        "#path_train = '../input/train/'\n",
        "#path_test = '../input/test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NWV7SsNT8ygE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build U-Net model\n",
        "input_img = Input((im_height, im_width, im_chan), name='img')\n",
        "input_features = Input((n_features, ), name='feat')\n",
        "\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (input_img)\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "# Join features information in the depthest layer\n",
        "f_repeat = RepeatVector(8*8)(input_features)\n",
        "f_conv = Reshape((8, 8, n_features))(f_repeat)\n",
        "p4_feat = concatenate([p4, f_conv], -1)\n",
        "\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4_feat)\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "#check out this skip connection thooooo\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[input_img, input_features], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gPvdnZ_X85ub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FW4H6CTa9A3S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "train_ids = next(os.walk(train_path+\"images\"))[2]\n",
        "\n",
        "\n",
        "# Get and resize train images and masks\n",
        "X = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.float32)\n",
        "y = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.float32)\n",
        "X_feat = np.zeros((len(train_ids), n_features), dtype=np.float32)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = train_path\n",
        "    \n",
        "    # Depth\n",
        "    #X_feat[n] = depth.loc[id_.replace('.png', ''), 'z']\n",
        "    \n",
        "    # Load X\n",
        "    img = load_img(path + '/images/' + id_, grayscale=True)\n",
        "    x_img = img_to_array(img)\n",
        "    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "    \n",
        "    # Create cumsum x\n",
        "    x_center_mean = x_img[border:-border, border:-border].mean()\n",
        "    x_csum = (np.float32(x_img)-x_center_mean).cumsum(axis=0)\n",
        "    x_csum -= x_csum[border:-border, border:-border].mean()\n",
        "    x_csum /= max(1e-3, x_csum[border:-border, border:-border].std())\n",
        "\n",
        "    # Load Y\n",
        "    mask = img_to_array(load_img(path + '/masks/' + id_, grayscale=True))\n",
        "    mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
        "\n",
        "    # Save images\n",
        "    X[n, ..., 0] = x_img.squeeze() / 255\n",
        "    X[n, ..., 1] = x_csum.squeeze()\n",
        "    y[n] = mask / 255\n",
        "\n",
        "print('Done!')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWYqSreg9Sjh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, X_feat_train, X_feat_valid, y_train, y_valid = train_test_split(X, X_feat, y, test_size=0.15, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1sXAPHG9lUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ReduceLROnPlateau(patience=3, verbose=1),\n",
        "    ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]\n",
        "\n",
        "results = model.fit({'img': X_train, 'feat': X_feat_train}, y_train, batch_size=16, epochs=50, callbacks=callbacks,\n",
        "                    validation_data=({'img': X_valid, 'feat': X_feat_valid}, y_valid))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}